<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Selective Underfitting: a new lens to understand how diffusion models generalize, when they underfit, and why popular training recipes like DiT/REPA work.">
  <meta name="keywords" content="diffusion models, selective underfitting, score matching, REPA, DiT">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Selective Underfitting in Diffusion Models</title>
  <link rel="canonical" href="https://selective-underfitting.github.io/"/>

  <!-- MathJax for LaTeX rendering (optional) -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script>
    window.MathJax = { tex: { inlineMath: [['$', '$'], ['\(', '\)']], displayMath: [['$$','$$'], ['\[','\]']] } };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <!-- (Optional) Analytics – fill in your ID or remove -->
  <script>
    // window.dataLayer = window.dataLayer || [];
    // function gtag(){dataLayer.push(arguments);} gtag('js', new Date());
    // gtag('config', 'G-XXXXXXXXXX');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <!-- Bulma / Icons / Local styles (match FlexMDM structure) -->
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <style>
    /* Minimal extras if ./static/css/index.css is empty */
    .publication-title { letter-spacing: -0.02em; }
    .hero.is-primary { background: linear-gradient(180deg,#0f1221,#14182c); }
    .teaser img { border-radius: 10px; box-shadow: 0 12px 32px rgba(0,0,0,.25); }
    .fancy-table { width: 100%; border-collapse: collapse; }
    .fancy-table th,.fancy-table td{ border:1px solid #e6e6e6; padding:8px 10px; }
    .fancy-table th{ background:#f6f7fb; }
    .section .subtitle strong{ font-weight:700; }
    .tagline { color:#6b7280; margin-top:.25rem; }
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- HERO -->
<section class="hero is-white">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Selective Underfitting in Diffusion Models</h1>
          <p class="tagline">A new rule of understandig diffusion models for how diffusion models learn, generalize, and scale.</p>

          <div class="is-size-5 publication-authors" style="margin-top:10px">
            <span class="author-block"><a href="https://kiwhan.dev/" target="_blank">Kiwhan Song<sup>*</sup><sup>1</sup>,</span>
            <span class="author-block"><a href="https://jaeyeonkim01.github.io/" target="_blank">Jaeyeon Kim<sup>*</sup><sup>2</sup>,</span>
            <span class="author-block"><a href="https://sitanchen.com" target="_blank">Sitan Chen</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://yilundu.github.io" target="_blank">Yilun Du</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://shamulent.github.io" target="_blank">Sham Kakade</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://vsitzmann.github.io/" target="_blank">Vincent Sitzmann</a><sup>2</sup></span>
          </div>
          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>*</sup>equal contribution</span>
            <span class="author-block"><sup>1</sup>Harvard</span>
            <span class="author-block"><sup>2</sup>MIT</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2510.01378" class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://typefully.com/t/xCWbsZ1" class="external-link button is-normal is-rounded is-light" target="_blank" rel="noopener">
                  <span class="icon"><i class="fab fa-x-twitter"></i></span>
                  <span>Thread</span>
                </a>
              </span>
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>

<!-- INTRO / SUMMARY FROM THREAD -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            Diffusion models have emerged as the principal paradigm for generative modeling across various domains. During training, they learn the score function, which in turn is used to generate samples at inference. Despite their success, they face an apparent paradox: if training were perfect, they would learn the empirical score function–the score with respect to the finite training data–and simply replicate the training data at inference, never generating novel samples.
          </p>
          <p>
            Recent work has sought to resolve this paradox by arguing that diffusion models “globally” underfit the empirical score and suggest that inductive bias or smoothness of neural networks are the reason for this, including (Kamb &amp; Ganguli 2024; Niedoba et al. 2024; Scarvelis et al. 2023; Pidstrigach 2022; Yoon et al. 2023; Yi et al. 2023). Instead, we argue that understanding diffusion models requires us to investigate not just how they underfit the empirical score, but where they underfit. We show that diffusion models do not underfit in a certain region of the space and selectively underfit beyond it. This provides a novel lens for explaining diffusion models’ behavior.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- REGIONS SECTION -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Selective Underfitting</h2>
    <div class="content">
      <ul>
        <p>
          We first distinguish two regions of the space: <strong>supervision region</strong> and <strong>extrapolation region</strong>. Error between the learned score and the empirical score decreases in the supervision region (X underfitting, blue line) but increases in the extrapolation region (O underfitting, red line) as models improve with better FID scores. These two regions can be further characterized as follows:        
        </p>
        <ul>
          <li><strong>Supervision region</strong>: where the noisy training samples concentrated with a high probability. A model is supervised to learn the empirical score in this region (blue shells).</li>
          <li><strong>Extrapolation region</strong>: where the model is actually queried during inference. A model is not supervised to learn the empirical score in this region (red region).</li>
          <li>In supervision region, the learned and empirical scores are <strong>sufficiently close</strong> that the model reproduces the training images when sampling starts from there.</li> 
        </ul>
        <p>
          Therefore, we claim that the right way to understand diffusion models is to think of them as operating by <strong>(1)</strong> approximating the empirical score within the supervision region and <strong>(2)</strong> extrapolating it to the extrapolation region, which is ultimately used at inference time.
        </p>
      </ul>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Generalization</h2>
    <div class="content">
      <ul>
        <li><strong>Generalization depends on region sizes</strong>: enlarging supervision region degrades generalization, independent of architecture (SiT, U-Net).</li>
        <li><strong>FID decomposition</strong>: via a scaling law, we split FID into (i) supervision loss (fit to empirical score) and (ii) <em>extrapolation efficiency</em> (how effectively a given supervision loss turns into FID gains).</li>
      </ul>
    </div>
  </div>
</section>

<!-- ERROR CURVES -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Selective Underfitting Curves</h2>
    <div class="columns is-vcentered">
      <div class="column is-half">
        <img src="./static/images/dummy.jpg" alt="Error curves placeholder"/>
        <p class="has-text-grey is-size-7">Dummy figure – blue: supervision error ↓ with scale; red: extrapolation error ↑.</p>
      </div>
      <div class="column is-half">
        <div class="content">
          We observe decreasing error between learned and empirical scores within supervision, but increasing error in extrapolation as models scale. This provides direct, quantitative evidence for <em>selective</em> rather than global underfitting.
        </div>
      </div>
    </div>
  </div>
</section>

<!-- GENERALIZATION / SCALING -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Generalization & Scaling</h2>
    <div class="content">
      <ul>
        <li><strong>Generalization depends on region sizes</strong>: enlarging supervision region degrades generalization, independent of architecture (SiT, U-Net).</li>
        <li><strong>FID decomposition</strong>: via a scaling law, we split FID into (i) supervision loss (fit to empirical score) and (ii) <em>extrapolation efficiency</em> (how effectively a given supervision loss turns into FID gains).</li>
      </ul>
    </div>
  </div>
</section>

<!-- WHY RECIPES WORK -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Why do DiT and REPA work?</h2>
    <div class="columns is-vcentered">
      <div class="column is-half">
        <img src="./static/images/dummy.jpg" alt="FID decomposition placeholder"/>
        <p class="has-text-grey is-size-7">Dummy figure – swap with your FID decomposition plot.</p>
      </div>
      <div class="column is-half">
        <div class="content">
          <ul>
            <li><strong>REPA</strong> mainly boosts <em>extrapolation efficiency</em> with minimal change in supervision loss.</li>
            <li><strong>Transformers (DiT)</strong> trail U-Nets in extrapolation efficiency but excel in FLOPs→supervision loss, yielding better compute efficiency (FLOPs→FID).</li>
            <li>Methods like <em>RePA</em> and <em>ReDi</em> align score outputs with learned representations, improving behavior in underfitting regions.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- TAKEAWAYS -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Takeaways</h2>
    <div class="content">
      <ol>
        <li>Diffusion models do not underfit everywhere; they underfit <strong>selectively</strong> in distinct regions.</li>
        <li>The relative sizes of supervision/extrapolation regions control generalization.</li>
        <li>Decomposing FID into supervision vs. extrapolation efficiency explains why recipes like REPA and DiT/SiT work.</li>
      </ol>
    </div>
  </div>
</section>

<!-- BIBTEX -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
<pre><code>@article{song2025selective,
  title   = {Selective Underfitting in Diffusion Models},
  author  = {Song, Kiwhan and Kim, Jaeyeon and Chen, Sitan and Du, Yilun and Kakade, Sham and Sitzmann, Vincent},
  journal = {arXiv preprint arXiv:2510.01378},
  year    = {2025}
}</code></pre>
  </div>
</section>

<!-- FOOTER -->
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="#" class="external-link" aria-disabled="true">
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.</p>
          <p>This webpage is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> and the FlexMDM site template.</p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>